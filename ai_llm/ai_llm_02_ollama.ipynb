{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4f1949-9234-4ef4-a94a-fae2b3a34c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -qU pip\n",
    "# %pip install -qU langchain\n",
    "# %pip install -q langchain-community\n",
    "# %pip install -q langchain-ollama\n",
    "# %pip install -q ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbf6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Emissary-Tech/legit-rag/blob/main/src/components/router.py\n",
    "# https://python.langchain.com/docs/integrations/llms/ollama/\n",
    "# https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html#systemmessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6aa523-5ed2-43b3-ada0-dcbdbdf7d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b23de6f-cddd-41d0-ae82-9325ed64189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM (\n",
    "        base_url=\"http://localhost:11434/\",\n",
    "        # model=\"llama3.1:latest\",\n",
    "        model=\"llama3.2:3b\",\n",
    "        temperature=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a959162d-4554-41af-990d-910d53f0d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a query router that categorizes incoming queries into three response types.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return EXACTLY ONE of these values in uppercase: ANSWER, CLARIFY, or REJECT\n",
    "\n",
    "CLASSIFICATION RULES:\n",
    "\n",
    "ANSWER if ALL of these conditions are met:\n",
    "- Query has a clear, single objective\n",
    "- Sufficient context is provided\n",
    "- Can be answered with factual information\n",
    "- Falls within general knowledge domains\n",
    "Examples:\n",
    "- \"What is the capital of France?\"\n",
    "- \"How does photosynthesis work?\"\n",
    "- \"When was the iPhone first released?\"\n",
    "\n",
    "CLARIFY if ANY of these conditions are met:\n",
    "- Multiple possible interpretations\n",
    "- Missing critical details\n",
    "- Time period/context not specified\n",
    "- Scope is too broad\n",
    "Examples:\n",
    "- \"What's the best one?\"\n",
    "- \"How much does it cost?\"\n",
    "- \"Why did they do that?\"\n",
    "\n",
    "REJECT if ANY of these conditions are met:\n",
    "- Promotes harm or illegal activities\n",
    "- Contains hate speech or discriminatory content\n",
    "- Requests personal/private information\n",
    "- Completely nonsensical or impossible to parse\n",
    "Examples:\n",
    "- \"How do I hack someone's email?\"\n",
    "- \"Tell me private details about person X\"\n",
    "- \"§¶∆∆˚¬˜µ≤≥\"\n",
    "\n",
    "Response should contain ONLY the classification word, nothing else.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f4d9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"Could you help develop style guidelines for our technical documentation that balance accessibility for non-native English speakers while maintaining precise terminology for our AI/ML products? We have some existing documentation but aren't sure if it follows W3C standards, and our team is split between those who prefer academic writing style versus those advocating for a more conversational tone. Specifically, we want to know about using passive voice, technical jargon translation, and correct formatting for code snippets - though we haven't decided which programming languages to prioritize yet.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926a3db2-172d-45b5-91d8-fe8f97595e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        SystemMessage(system_prompt),\n",
    "        HumanMessage(input_text),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b3b38a5-e30b-42af-a5cb-f75fe11e509f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REJECT'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a0a75-dba0-457a-963a-a0cb89fbb043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
